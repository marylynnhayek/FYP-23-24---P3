import openpyxl
import numpy as np
from transformers import AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
import torch
import pandas as pd
import os
 
# Function to Load an Excel file and Sheet:
def load_sheet(filename, sheet_name):
    print(f"Loading sheet '{sheet_name}' from file '{filename}'...")
    try:
        wb = openpyxl.load_workbook(filename=filename)
        if sheet_name in wb.sheetnames:
            print("Sheet loaded successfully.")
            return wb[sheet_name], wb.active
        else:
            print(f"Warning: Sheet '{sheet_name}' not found in the workbook.")
            return None, None
    except Exception as e:
        print(f"Error occurred while loading sheet: {e}")
        return None, None

# Append data to an Excel Sheet:
def write_on_sheet(sheet, data, row_index):
    print("Append data to the sheet...")  
    for col_index, value in enumerate(data):
        if isinstance(value, np.ndarray):  
            value = value.item()  
        sheet.cell(row=row_index + 1, column=col_index + 1).value = value
 
# Iterate through the sheet and store the values of each cell in its respective list:
def get_linkedin_scraped_data(sheet, iso_sheet=True):
    print("Extracting skills from the sheet...")
    email_list = []
    skills_list = []
     
    for row in sheet.iter_rows(values_only=True):
        if len(row) > 2:
            email = row[0]
            skills = row[1]
            email_list.append(email)
            skills_list.append(skills)
        else:
            print("Warning: Row has fewer columns than expected.")
            break
    print("Data extracted successfully from the sheet.")
    return email_list, skills_list
 
def calculate_similarity(linkedin_data_row, ws_similarity):
    print("Calculating similarity between email and skills...")

    email_body = linkedin_data_row['email']
    skills = linkedin_data_row['skills']

    sentences = [email_body, skills]

    print("Loading BERT model and tokenizer...")
    model_name = 'sentence-transformers/bert-base-nli-mean-tokens'
    print(f"Loading tokenizer for model '{model_name}'...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    print("Tokenizer loaded successfully.")
    print(f"Loading model '{model_name}'...")
    model = AutoModel.from_pretrained(model_name)
    print("Model loaded successfully.")
    
    temp_similarity_scores = []

    tokens = {'input_ids': [], 'attention_mask': []}

    for sentence in sentences:
        new_tokens = tokenizer.encode_plus(sentence, max_length=128, truncation=True, padding='max_length', return_tensors='pt')
        tokens['input_ids'].append(new_tokens['input_ids'][0])
        tokens['attention_mask'].append(new_tokens['attention_mask'][0])

    tokens['input_ids'] = tuple(tokens['input_ids'])
    tokens['attention_mask'] = tuple(tokens['attention_mask'])
 
    tokens['input_ids'] = torch.stack(tokens['input_ids'])
    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])
 
    outputs = model(**tokens)
    embeddings = outputs.last_hidden_state
 
    attention = tokens['attention_mask']
    mask = attention.unsqueeze(-1).expand(embeddings.shape)
    mask_embeddings = embeddings * mask

    summed = torch.sum(mask_embeddings, 1)
    counts = torch.clamp(mask.sum(1), min=1e-9)
    mean_pooled = summed / counts
    mean_pooled = mean_pooled.detach().numpy()

    similarity_score = cosine_similarity([mean_pooled[0]], [mean_pooled[1]])[0][0]
    
    print(f"Similarity Score between Email Body and Skills: {similarity_score}")
    print(f"Email Body: {email_body}")
    print(f"Skills: {skills}")

    ws_similarity.append([email_body, skills, similarity_score])
    temp_similarity_scores.append(similarity_score)

    return temp_similarity_scores

if __name__ == "__main__":
    linkedin_file = "LinkedIn_Data.xlsx"
    linkedin_sheet_name = "LinkedIn_Data"

    wb_linkedin, ws_linkedin = load_sheet(linkedin_file, linkedin_sheet_name)

    if ws_linkedin is not None:
        wb_similarity = openpyxl.Workbook()
        ws_similarity = wb_similarity.active
        ws_similarity.title = "Similarity_Scores"
        ws_similarity.append(["Email Body", "Skills", "Similarity Score"])

        for row in ws_linkedin.iter_rows(min_row=2, values_only=True):
            linkedin_data_row = {'email': row[0], 'skills': row[1]}
            similarity_score = calculate_similarity(linkedin_data_row, ws_similarity)
            print(f"Similarity Score: {similarity_score}")

        wb_similarity.save("Similarity_Scores.xlsx")
    else:
        print("Unable to load the LinkedIn sheet. Exiting.")