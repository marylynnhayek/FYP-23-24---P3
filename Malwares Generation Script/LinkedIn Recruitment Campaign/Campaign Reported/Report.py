import os
from bs4 import BeautifulSoup
from urllib.request import Request, urlopen

def collect_applicant_info():
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
 
    site = 'https://au.linkedin.com/in/marylynnelhayek'
 
    req = Request(site,headers=headers)
    page = urlopen(req)
 
    soup = BeautifulSoup(page, 'lxml')
    name = soup.find('h1', class_='top-card-layout__title font-sans text-lg papabear:text-xl font-bold leading-open text-color-text mb-0')
    if name:
        name = name.text.strip()
        print("Name:", name)
    else:
        print("Name not found")
        return None, None

    projects = soup.find_all('p', class_='show-more-less-text__text--less')
    if projects:
        project_list = [project.text.strip() for project in projects]
        print("Projects:", project_list)
    else:
        print("Projects not found")
        return None, None
    
    return name, project_list

def generate_report(name, projects):
    report_content = f"LinkedIn Profile Scraping Report for {name}\n\n"
    report_content += f"Name: {name}\n\n"
    report_content += "Projects:\n"
    for i, project in enumerate(projects, start=1):
        report_content += f"{i}. {project}\n"
    
    return report_content

def save_report_to_file(report_content, name):
    filename = f"{name}_linkedin_profile_report.txt"
    with open(filename, "w", encoding="utf-8") as file:
        file.write(report_content)
    print(f"Report saved to {filename}")


if __name__ == "__main__":
    name, projects = collect_applicant_info()

    if name and projects:
        report_content = generate_report(name, projects)
        save_report_to_file(report_content, name)
    else:
        print("Failed to collect applicant information.")